{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f37149-c4d4-4bb2-be40-33caccccdc92",
   "metadata": {},
   "source": [
    "# Python Text Analysis: Part 3 Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428bef9b-2ce9-456c-a260-9b72d79d6e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c923bb-7286-4d55-8002-684343a5a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf4a748-d43e-4c76-8eaa-ad504e5c3a51",
   "metadata": {},
   "source": [
    "## 🥊 Desafío 1: No coinciden\n",
    "\n",
    "¡Ahora te toca! En la siguiente celda, hemos preparado una lista de pares de sustantivos con \"café\". Por ejemplo, la palabra \"café\" se asocia con una bebida de café específica. Averigüemos qué bebida de café se considera más similar a \"café\" y cuál no.\n",
    "\n",
    "Completa el bucle \"for\" (dos celdas más abajo) para calcular la similitud de coseno entre cada par de palabras; es decir, usa la función \"similitud\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c4f076-005a-4176-93dd-60e681f6b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_nouns = [\n",
    "    ('coffee', 'espresso'),\n",
    "    ('coffee', 'cappuccino'),\n",
    "    ('coffee', 'latte'),\n",
    "    ('coffee', 'americano'),\n",
    "    ('coffee', 'irish'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa15ad5-b3fe-4871-8c07-bfa1bac58e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cosine similarities between each pair\n",
    "for w1, w2 in coffee_nouns:\n",
    "    similarity = wv.similarity(w1, w2)\n",
    "    print(f\"{w1}, {w2}, {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "wv = KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# Si aún no tienes 'wv' cargado, descomenta estas líneas para usar un modelo público:\n",
    "# import gensim.downloader as api\n",
    "# wv = api.load(\"glove-wiki-gigaword-100\")  # o \"word2vec-google-news-300\"\n",
    "\n",
    "coffee_nouns = [\n",
    "    ('coffee', 'espresso'),\n",
    "    ('coffee', 'cappuccino'),\n",
    "    ('coffee', 'latte'),\n",
    "    ('coffee', 'americano'),\n",
    "    ('coffee', 'irish'),\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for w1, w2 in coffee_nouns:\n",
    "    # Compatibilidad con Gensim 4.x:\n",
    "    in_vocab = getattr(wv, \"key_to_index\", None)\n",
    "    has_w1 = (w1 in wv.key_to_index) if in_vocab is not None else (w1 in wv)\n",
    "    has_w2 = (w2 in wv.key_to_index) if in_vocab is not None else (w2 in wv)\n",
    "\n",
    "    if not (has_w1 and has_w2):\n",
    "        print(f\"⚠️ OOV (fuera de vocabulario): {w1 if not has_w1 else ''} {w2 if not has_w2 else ''}\".strip())\n",
    "        continue\n",
    "\n",
    "    similarity = float(wv.similarity(w1, w2))\n",
    "    results.append((w1, w2, similarity))\n",
    "    print(f\"{w1:>7s} ↔ {w2:<11s}: {similarity:.4f}\")\n",
    "\n",
    "# Mostrar el más y el menos similar\n",
    "if results:\n",
    "    most_similar = max(results, key=lambda t: t[2])\n",
    "    least_similar = min(results, key=lambda t: t[2])\n",
    "    print(\"\\n🏆 Más similar a 'coffee':\", most_similar[1], f\"({most_similar[2]:.4f})\")\n",
    "    print(\"🥄 Menos similar a 'coffee':\", least_similar[1], f\"({least_similar[2]:.4f})\")\n",
    "else:\n",
    "    print(\"No se pudieron calcular similitudes (todas las palabras OOV).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8831cc57",
   "metadata": {},
   "source": [
    "**✅ Salida esperada:**\n",
    "\n",
    " coffee ↔ espresso   : 0.6640  \n",
    " coffee ↔ cappuccino : 0.5371  \n",
    " coffee ↔ latte      : 0.4755  \n",
    " coffee ↔ americano  : 0.0107  \n",
    " coffee ↔ irish      : 0.2293  \n",
    "\n",
    "🏆 Más similar a 'coffee': espresso (0.6640)  \n",
    "🥄 Menos similar a 'coffee': americano (0.0107)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4df5c2a-3980-43b2-93c0-5b6c1a6b6912",
   "metadata": {},
   "source": [
    "A continuación, investiguemos los verbos comúnmente asociados con la preparación de café. Analicemos el caso de uso de la función doesnt_match y luego úsela para identificar el verbo que no parece corresponder.\n",
    "\n",
    "¡Agregue más verbos a la lista!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe8838e-c48f-49f0-9a0c-f135e1fb7d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_verbs = ['brew', 'drip', 'pour', 'make', 'grind', 'roast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc36a9d-08c2-47ca-8564-0c3d76fde4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the word that doesn't belong to the list\n",
    "verb_dosent_match = wv.doesnt_match(coffee_verbs)\n",
    "verb_dosent_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc470586",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "coffee_verbs = ['brew', 'drip', 'pour', 'make', 'grind', 'roast']\n",
    "\n",
    "# verificar que las palabras existan en el vocabulario\n",
    "print([w for w in coffee_verbs if w not in wv.key_to_index])\n",
    "\n",
    "# encontrar la que no encaja\n",
    "verb_doesnt_match = wv.doesnt_match(coffee_verbs)\n",
    "print(\"Verbo que no encaja:\", verb_doesnt_match)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96ab141",
   "metadata": {},
   "source": [
    "**🔎 Explicación paso a paso**\n",
    "\n",
    "El código revisa si los verbos están en el vocabulario del modelo y usa embeddings de palabras para encontrar cuál de ellos no pertenece semánticamente al grupo. Se usa un modelo de embeddings de palabras (el objeto wv, de Gensim) para detectar qué palabra de la lista no “encaja” con las demás.\n",
    "\n",
    "Lo que hace cada parte:\n",
    "\n",
    "1. Definición de la lista  \n",
    "    coffee_verbs = ['brew', 'drip', 'pour', 'make', 'grind', 'roast']  \n",
    "    Se crea una lista de verbos relacionados con la preparación de café.\n",
    "\n",
    "2. Verificación de vocabulario  \n",
    "    print([w for w in coffee_verbs if w not in wv.key_to_index])  \n",
    "    wv.key_to_index contiene todas las palabras que conoce el modelo (wv).\n",
    "\n",
    "    Este print muestra cuáles de los verbos de la lista no existen en el vocabulario del modelo (OOV = out of vocabulary).  \n",
    "    Sirve para saber si habrá errores al calcular similitudes.\n",
    "\n",
    "3. Encontrar el “intruso”  \n",
    "    verb_doesnt_match = wv.doesnt_match(coffee_verbs)  \n",
    "    doesnt_match compara todos los embeddings de la lista.\n",
    "\n",
    "    Calcula qué palabra tiene la menor similitud promedio con las demás.  \n",
    "    Esa palabra se considera la que “no pertenece” al grupo.\n",
    "\n",
    "4. Mostrar resultado  \n",
    "    print(\"Verbo que no encaja:\", verb_doesnt_match)\n",
    "\n",
    "    Imprime el verbo detectado como intruso.\n",
    "\n",
    "    En este caso, lo más común es que devuelva \"make\", porque es un verbo muy genérico, mientras que los demás están más ligados a preparar café."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc77160",
   "metadata": {},
   "source": [
    "**✅ Salida esperada:**\n",
    "\n",
    "**Verbo que no encaja: make**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80ac569-8889-4dbd-aa5d-b0ae7314a0aa",
   "metadata": {},
   "source": [
    "## 🥊 Desafío 2: ¿Mujer es ama de casa?\n",
    "\n",
    "[Bolukbasi et al. (2016)](https://arxiv.org/pdf/1607.06520) es una investigación exhaustiva sobre el sesgo de género presente en las incrustaciones de palabras, y se centra principalmente en las analogías de palabras, especialmente aquellas que revelan estereotipos de género. Analicemos un par de ejemplos analizados en el artículo, utilizando la función `most_similiar` que acabamos de aprender.\n",
    "\n",
    "El siguiente bloque de código contiene algunos ejemplos que podemos pasar al argumento `positive`: queremos que la salida sea similar a, por ejemplo, `woman` y `chairman`, y mientras tanto, también especificamos que debe ser diferente a `man`. Imprimiremos el resultado superior indexando al elemento 0.\n",
    "\n",
    "Completemos el siguiente bucle `for`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4082d7e-9b2e-43dc-b7fa-b847889760be",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pair = [['woman', 'chairman'],\n",
    "                 ['woman', 'doctor'], \n",
    "                 ['woman', 'computer_programmer']]\n",
    "negative_word = 'man'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc9a002-fd48-4f8f-b677-842c8538a560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most similar word given positive and negative examples\n",
    "for example in positive_pair:\n",
    "    result = wv.most_similar(positive=example, negative=negative_word)\n",
    "    print(f\"man is to {example[1]} as woman is to {result[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ed50f",
   "metadata": {},
   "source": [
    "**📌 Función ama_de_casa.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5618031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "wv = KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# pares positivos (woman + target)\n",
    "positive_pair = [\n",
    "    ['woman', 'chairman'],\n",
    "    ['woman', 'doctor'],\n",
    "    ['woman', 'computer_programmer'],\n",
    "]\n",
    "negative_word = 'man'\n",
    "\n",
    "# --- Comprobación de vocabulario ---\n",
    "needed = {negative_word}\n",
    "for p in positive_pair:\n",
    "    needed.update(p)\n",
    "\n",
    "oov = [w for w in needed if w not in wv.key_to_index]\n",
    "if oov:\n",
    "    print(\"⚠️ Palabras fuera de vocabulario:\", oov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f0cd95",
   "metadata": {},
   "source": [
    "**🔎 Explicación paso a paso**\n",
    "\n",
    "Este código prepara un experimento de analogías con word embeddings y verifica que las palabras necesarias existan en el vocabulario del modelo antes de ejecutarlo.\n",
    "\n",
    "Resumen paso a paso:\n",
    "\n",
    "1. Importa librerías y carga un modelo preentrenado  \n",
    "    wv = KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "- Abre el modelo GoogleNews (≈1.5 GB) en formato Word2Vec binario.  \n",
    "- Si la ruta/archivo no existe, lanzará FileNotFoundError.  \n",
    "- Requiere bastante RAM.  \n",
    "2. Define pares “positivos” para analogías del tipo:\n",
    "    “woman + chairman − man ≈ ?”  \n",
    "    “woman + doctor − man ≈ ?”  \n",
    "    “woman + computer_programmer − man ≈ ?”\n",
    "\n",
    "3. Palabra “negativa”:  \n",
    "    negative_word = 'man'\n",
    "\n",
    "4. Verifica vocabulario (OOV):  \n",
    "    Crea el conjunto de todas las palabras que se usarán y lista las que no están en el vocabulario del modelo (wv.key_to_index):  \n",
    "        oov = [w for w in needed if w not in wv.key_to_index]  \n",
    "        if oov:  \n",
    "            print(\"⚠️ Palabras fuera de vocabulario:\", oov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47df5a4f",
   "metadata": {},
   "source": [
    "**✅ Salida esperada:**  \n",
    "man is to chairman as woman is to chairwoman (score=0.7713)  \n",
    "man is to doctor as woman is to gynecologist (score=0.7094)  \n",
    "man is to computer_programmer as woman is to homemaker (score=0.5627)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0142b3-545b-4f52-8e7b-2711e20abbd6",
   "metadata": {},
   "source": [
    "## 🥊 Desafío 3: Construir un Eje Semántico\n",
    "\n",
    "¡Ahora te toca! Tenemos dos conjuntos de palabras clave para \"female\" y \"male\". Estos son ejemplos de palabras probadas en Bolukbasi et al., 2016. Obtendremos las incrustaciones de estas palabras de glove para calcular el eje de género.\n",
    "\n",
    "La celda de la función `get_semaxis` proporciona código inicial. Completa la función. Si todo se ejecuta, el tamaño de la incrustación del eje semántico debería ser igual al tamaño del vector de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72fb395-796d-410a-a3fa-f14c55b36f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = api.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bac1297-5aca-4cdf-bd2b-bd0c71cfd6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two sets of pole words (examples from Bolukbasi et al., 2016)\n",
    "female = ['she', 'woman', 'female', 'daughter', 'mother', 'girl']\n",
    "male = ['he', 'man', 'male', 'son', 'father', 'boy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815d6225-015a-4ad9-98e6-f05a4aabbbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_semaxis(list1, list2, model, embedding_size):\n",
    "    '''Calculate the embedding of a semantic axis given two lists of pole words.'''\n",
    "\n",
    "    # STEP 1: Get the embeddings for terms in each list\n",
    "    v_plus = [model[term] for term in list1]\n",
    "    v_minus = [model[term] for term in list2]\n",
    "\n",
    "    # Step 2: Calculate the mean embeddings for each list\n",
    "    v_plus_mean = np.mean(v_plus, axis=0)\n",
    "    v_minus_mean = np.mean(v_minus, axis=0)\n",
    "\n",
    "    # Step 3: Get the difference between two means\n",
    "    sem_axis = v_plus_mean - v_minus_mean\n",
    "\n",
    "    # Sanity check\n",
    "    assert sem_axis.size == embedding_size\n",
    "    \n",
    "    return sem_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe27243-1c45-4433-8f33-559c121c98b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08418201,  0.30625182, -0.23662159,  0.02026337, -0.00296998,\n",
       "        0.6195349 ,  0.01208681,  0.06963003,  0.49099812, -0.20878893,\n",
       "        0.00934163, -0.44707334,  0.48806185,  0.19471335,  0.20141667,\n",
       "        0.0832995 , -0.4245833 , -0.08612835,  0.47612852, -0.05129966,\n",
       "        0.31475997,  0.49075842,  0.12465019,  0.26685053,  0.29776838,\n",
       "        0.14211655, -0.09953564,  0.2320785 , -0.01026282, -0.30585438,\n",
       "       -0.1335001 ,  0.21605133,  0.10961549, -0.03373036, -0.13584831,\n",
       "       -0.12131716, -0.14671612, -0.04348468,  0.06151834, -0.3654362 ,\n",
       "       -0.06193466, -0.17093089,  0.5058871 , -0.44872418,  0.05962732,\n",
       "       -0.18274659,  0.24432765, -0.3396697 ,  0.00442566,  0.10554916],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plug in the gender lists to calculate the semantic axis for gender\n",
    "gender_axis = get_semaxis(list1=female, \n",
    "                          list2=male, \n",
    "                          model=glove, \n",
    "                          embedding_size=50)\n",
    "gender_axis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
